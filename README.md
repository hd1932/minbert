# minbert

This project leverages the BERT model to enhance sentiment analysis, paraphrase detection, and semantic textual similarity tasks. It begins with an implementation of the BERT modelâ€™s multi-head self-attention mechanism and transformer layers with an optimizer using the step function of the Adam Optimizer based on Decoupled Weight Decay Regularization. Then, I implemented a multitask classifier using task-specific layers, unique loss functions, and a novel caching mechanism during pretraining to enhance efficiency. 
